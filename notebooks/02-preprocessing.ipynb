{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "b610331f",
   "metadata": {},
   "source": [
    "# 02-preprocessing.ipynb\n",
    "Preprocessing notebook: clean PhishTank dump, extract domains and safe flags, and extract URLs/senders from the Enron mail corpus (if available).\n",
    "\n",
    "**Safety note:** this notebook does NOT fetch or visit any URLs. It only parses text and extracts features. Do not add code that performs live HTTP requests without sandboxing."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "07ccbb8b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Note: you may need to restart the kernel to use updated packages.\n",
      "python 3.10.12 (main, Nov  6 2024, 20:22:13) [GCC 11.4.0]\n"
     ]
    }
   ],
   "source": [
    "# 1. Environment (use inside notebook)\n",
    "%pip install --quiet pandas tldextract python-whois ipaddress\n",
    "import sys\n",
    "print('python', sys.version.splitlines()[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "db5b5463",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2. Imports and helpers\n",
    "import os\n",
    "import re\n",
    "import csv\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import tldextract\n",
    "import ipaddress\n",
    "from datetime import datetime\n",
    "\n",
    "# fix: escape the double-quote inside the regex string so the string literal is valid\n",
    "URL_PATTERN = re.compile(r\"https?://[^\\s'\\\"<>]+\", flags=re.IGNORECASE)\n",
    "\n",
    "def extract_urls_from_text(text):\n",
    "    if pd.isna(text):\n",
    "        return []\n",
    "    return URL_PATTERN.findall(str(text))\n",
    "\n",
    "def extract_domain(url):\n",
    "    # returns domain.suffix or empty string for invalid input\n",
    "    try:\n",
    "        ext = tldextract.extract(str(url))\n",
    "        if ext.suffix:\n",
    "            return f\"{ext.domain}.{ext.suffix}\"\n",
    "        return ext.domain or ''\n",
    "    except Exception:\n",
    "        return ''\n",
    "\n",
    "def is_ip_host(url):\n",
    "    try:\n",
    "        host = re.findall(r\"https?://([^/]+)/?\", str(url))\n",
    "        if not host:\n",
    "            return False\n",
    "        h = host[0]  # may include port\n",
    "        h = h.split(':')[0]\n",
    "        ipaddress.ip_address(h)\n",
    "        return True\n",
    "    except Exception:\n",
    "        return False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "28460767",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Raw PhishTank file not found: data/raw/verified_online.csv\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>phish_id</th>\n",
       "      <th>url</th>\n",
       "      <th>domain</th>\n",
       "      <th>phish_detail_url</th>\n",
       "      <th>submission_time</th>\n",
       "      <th>verified</th>\n",
       "      <th>verification_time</th>\n",
       "      <th>online</th>\n",
       "      <th>target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Empty DataFrame\n",
       "Columns: [phish_id, url, domain, phish_detail_url, submission_time, verified, verification_time, online, target]\n",
       "Index: []"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 3. Load and clean PhishTank CSV -> produce data/processed/phish_url_summary.csv\n",
    "RAW_PHISH = os.path.join('data','raw','verified_online.csv')\n",
    "OUT_DIR = os.path.join('data','processed')\n",
    "os.makedirs(OUT_DIR, exist_ok=True)\n",
    "PHISH_SUMMARY_OUT = os.path.join(OUT_DIR,'phish_url_summary.csv')\n",
    "\n",
    "def process_phishtank(raw_path=RAW_PHISH, out_path=PHISH_SUMMARY_OUT):\n",
    "    if not os.path.exists(raw_path):\n",
    "        print(f'Raw PhishTank file not found: {raw_path}')\n",
    "        return pd.DataFrame(columns=['phish_id','url','domain','phish_detail_url','submission_time','verified','verification_time','online','target'])\n",
    "    # read with pandas, keep relevant columns if present\n",
    "    df = pd.read_csv(raw_path, dtype=str, keep_default_na=False)\n",
    "    # normalize column names (in case header differs)\n",
    "    expected = ['phish_id','url','phish_detail_url','submission_time','verified','verification_time','online','target']\n",
    "    cols = [c for c in expected if c in df.columns]\n",
    "    df = df[cols].copy()\n",
    "    # ensure url column exists\n",
    "    if 'url' not in df.columns:\n",
    "        # try common alternatives\n",
    "        candidates = [c for c in df.columns if 'url' in c.lower()]\n",
    "        if candidates:\n",
    "            df = df.rename(columns={candidates[0]:'url'})\n",
    "        else:\n",
    "            print('No url column found in PhishTank file')\n",
    "            return pd.DataFrame(columns=['phish_id','url','domain','phish_detail_url','submission_time','verified','verification_time','online','target'])\n",
    "    df['url'] = df['url'].astype(str)\n",
    "    # extract domain and flags\n",
    "    df['domain'] = df['url'].apply(extract_domain)\n",
    "    df['is_ip'] = df['url'].apply(is_ip_host)\n",
    "    # reduce to canonical columns\n",
    "    out_cols = [c for c in ['phish_id','url','domain','is_ip','phish_detail_url','submission_time','verified','verification_time','online','target'] if c in df.columns or c in ['is_ip','domain']]\n",
    "    df_out = df.reindex(columns=out_cols)\n",
    "    df_out.to_csv(out_path, index=False)\n",
    "    print(f'Wrote processed PhishTank summary to {out_path} with shape {df_out.shape}')\n",
    "    return df_out\n",
    "\n",
    "# run processing now (safe: no network calls)\n",
    "phish_summary = process_phishtank()\n",
    "phish_summary.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "4d733685",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Enron maildir not found: data/raw/enron_emails\n"
     ]
    }
   ],
   "source": [
    "# 4. Extract URLs from Enron maildir (if available) and save senders & urls\n",
    "ENRON_DIR = os.path.join('data','raw','enron_emails')\n",
    "ENRON_URLS_OUT = os.path.join(OUT_DIR,'enron_urls.csv')\n",
    "ENRON_SENDERS_OUT = os.path.join(OUT_DIR,'enron_senders.csv')\n",
    "\n",
    "def extract_enron(enron_dir=ENRON_DIR, urls_out=ENRON_URLS_OUT, senders_out=ENRON_SENDERS_OUT):\n",
    "    if not os.path.exists(enron_dir):\n",
    "        print(f'Enron maildir not found: {enron_dir}')\n",
    "        return pd.DataFrame(columns=['url']), pd.DataFrame(columns=['sender'])\n",
    "    rows = []\n",
    "    senders = []\n",
    "    for root, _, files in os.walk(enron_dir):\n",
    "        for fname in files:\n",
    "            path = os.path.join(root, fname)\n",
    "            try:\n",
    "                with open(path, 'r', errors='ignore') as f:\n",
    "                    text = f.read()\n",
    "                    urls = extract_urls_from_text(text)\n",
    "                    for u in urls:\n",
    "                        rows.append({'url': u})\n",
    "                    # try to get From header if present\n",
    "                    m = re.search(r'^From:*(.+)$', text, flags=re.IGNORECASE|re.MULTILINE)\n",
    "                    if m:\n",
    "                        senders.append({'sender': m.group(1).strip()})\n",
    "            except Exception:\n",
    "                continue\n",
    "    df_urls = pd.DataFrame(rows).drop_duplicates().reset_index(drop=True)\n",
    "    df_senders = pd.DataFrame(senders).drop_duplicates().reset_index(drop=True)\n",
    "    if not df_urls.empty:\n",
    "        df_urls.to_csv(urls_out, index=False)\n",
    "        print(f'Wrote {len(df_urls)} extracted Enron URLs to {urls_out}')\n",
    "    else:\n",
    "        print('No URLs extracted from Enron corpus (or corpus missing)')\n",
    "    if not df_senders.empty:\n",
    "        df_senders.to_csv(senders_out, index=False)\n",
    "        print(f'Wrote {len(df_senders)} Enron senders to {senders_out}')\n",
    "    return df_urls, df_senders\n",
    "\n",
    "enron_urls, enron_senders = extract_enron()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "e4ced7b1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Phish summary is empty (no raw data found or file empty)\n",
      "Enron URLs empty or not extracted\n"
     ]
    }
   ],
   "source": [
    "# 5. Quick checks and simple unit-style assertions\n",
    "# ensure output files exist when dataframes non-empty\n",
    "if not phish_summary.empty:\n",
    "    assert os.path.exists(PHISH_SUMMARY_OUT), 'Processed phish summary missing'\n",
    "    print('Phish summary OK:', phish_summary.shape)\n",
    "else:\n",
    "    print('Phish summary is empty (no raw data found or file empty)')\n",
    "\n",
    "if 'enron_urls' in globals() and not enron_urls.empty:\n",
    "    assert os.path.exists(ENRON_URLS_OUT), 'Enron URLs output missing'\n",
    "    print('Enron URLs OK:', enron_urls.shape)\n",
    "else:\n",
    "    print('Enron URLs empty or not extracted')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "541936de",
   "metadata": {},
   "source": [
    "## Notes and next steps\n",
    "- This notebook creates `data/processed/phish_url_summary.csv` with columns `phish_id,url,domain,is_ip,...`.\n",
    "- It does NOT fetch or validate live URLs. For WHOIS or hosting features, add optional cells but run them in an isolated environment.\n",
    "- Use `phish_summary` as positive training examples and `enron_urls` as candidate negatives (verify and dedupe)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a994b53c",
   "metadata": {},
   "source": [
    "## CI / test snippet\n",
    "Use this command in CI to run tests for the notebook's helper functions (example):\n",
    "```\n",
    "pip install -r requirements.txt && pytest -q\n",
    "```"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
